{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f59879cabc55a5e",
   "metadata": {},
   "source": [
    "## Building a Bring Your Own Browser (BYOB) Tool for Web Browsing and Summarization\n",
    "\n",
    "**Disclaimer: This cookbook is for educational purposes only. Ensure that you comply with all applicable laws and service terms when using web search and scraping technologies. This cookbook will restrict the search to openai.com domain to retrieve the public information to illustrate the concepts.**\n",
    "\n",
    "Large Language Models (LLMs) such as GPT-4o have a knowledge cutoff date, which means they lack information about events that occurred after that point. In scenarios where the most recent data is essential, it's necessary to provide LLMs with access to current web information to ensure accurate and relevant responses.\n",
    "\n",
    "In this guide, we will build a Bring Your Own Browser (BYOB) tool using Python to overcome this limitation. Our goal is to create a system that provides up-to-date answers in your application, including the most recent developments such as the latest product launches by OpenAI. By integrating web search capabilities with an LLM, we'll enable the model to generate responses based on the latest information available online.\n",
    "\n",
    "While you can use any publicly available search APIs, we'll utilize Google's Custom Search API to perform web searches. The retrieved information from the search results will be processed and passed to the LLM to generate the final response through Retrieval-Augmented Generation (RAG).\n",
    "\n",
    "**Bring Your Own Browser (BYOB)** tools allow users to perform web browsing tasks programmatically. In this notebook, we'll create a BYOB tool that:\n",
    "\n",
    "**#1. Set Up a Search Engine:** Use a public search API, such as Google's Custom Search API, to perform web searches and obtain a list of relevant search results.  \n",
    "\n",
    "**#2. Build a Search Dictionary:** Collect the title, URL, and a summary of each web page from the search results to create a structured dictionary of information.  \n",
    "\n",
    "**#3. Generate a RAG Response:** Implement Retrieval-Augmented Generation (RAG) by passing the gathered information to the LLM, which then generates a final response to the user's query.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25223c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# search_systemPrompt = \"\"\"\n",
    "# **System Instruction:**\n",
    "# You are an expert API documentation assistant. Your task is to assist users in extracting API endpoint information from the provided search results, synthesize the relevant details from online sources, and generate a YAML configuration for the given API endpoint.\n",
    "\n",
    "# **User Input Example:**\n",
    "# \"Find details about the Figma API endpoint most likely to get_team_projects\"\n",
    "\n",
    "# **Expected Output:**\n",
    "# 1. Perform a search query to find reliable and updated documentation for the specified API endpoint.\n",
    "# 2. Extract the relevant information, including endpoint details, HTTP method, parameters, and usage examples.\n",
    "# 3. Generate a YAML configuration based on the following template:\n",
    "# \"\"\"\n",
    "\n",
    "# userPrompt = \"The user will provide a dictionary of search results in JSON format for search query {search_term} Based on on the search results provided by the user, provide a detailed response to this query: **'{search_query}'**. Make sure to cite all the sources at the end of your answer.\"\n",
    "\n",
    "systemPrompt_final = \"\"\"\n",
    "**System Instruction:**\n",
    "You are an expert API documentation assistant. Your task is to assist users in finding API endpoint information using provided search terms, synthesize the relevant details from online sources, and generate a YAML configuration for the given API endpoint. The YAML should include standard fields such as name, description, method, endpoint URL, parameters, and any other necessary details.\n",
    "\n",
    "**User Input Example:**\n",
    "\"Find details about the Figma API endpoint most likely to get_team_projects and generate a YAML configuration.\"\n",
    "\n",
    "**Expected Output:**\n",
    "1. Perform a search query to find reliable and updated documentation for the specified API endpoint.\n",
    "2. Extract the relevant information, including endpoint details, HTTP method, parameters, and usage examples.\n",
    "3. Generate a YAML configuration based on the following template:\n",
    "\n",
    "```yaml\n",
    "name: <API Endpoint Name Always start with the service provider name, like figma_get_team_projects, serpapi_google_search>\n",
    "servers:\n",
    "  - url: <API Service Provider Documentation URL>\n",
    "    description: Optional server description, e.g. Main (production) server\n",
    "description: <Brief Description of the API Endpoint>\n",
    "method: <HTTP Method>\n",
    "endpoint: <Full and Complete API Endpoint URL, like https://api.server.com/v1/projects>\n",
    "parameters:\n",
    "  - name: <Parameter Name>\n",
    "    type: <Data Type>\n",
    "    required: <true/false>\n",
    "    description: <Description>\n",
    "example_request: |\n",
    "  <Example cURL or HTTP Request>\n",
    "example_response: |\n",
    "  <Example API Response>\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "- Replace `<placeholders>` with the extracted API information.\n",
    "- Ensure the YAML structure is complete and adheres to standard YAML formatting rules.\n",
    "\n",
    "**Response Example:**\n",
    "Here is the YAML configuration for the Twitter API \"search tweets\" endpoint:\n",
    "\n",
    "```yaml\n",
    "name: Twitter API - Search Tweets\n",
    "description: Allows querying Twitter's recent tweets based on search terms.\n",
    "method: GET\n",
    "endpoint: https://api.twitter.com/2/tweets/search/recent\n",
    "parameters:\n",
    "  - name: query\n",
    "    type: string\n",
    "    required: true\n",
    "    description: The search query to run against tweets.\n",
    "  - name: max_results\n",
    "    type: integer\n",
    "    required: false\n",
    "    description: Maximum number of results to return (10–100).\n",
    "  - name: tweet.fields\n",
    "    type: string\n",
    "    required: false\n",
    "    description: A comma-separated list of additional fields to include in the response.\n",
    "example_request: |\n",
    "  curl -X GET \"https://api.twitter.com/2/tweets/search/recent?query=chatgpt&max_results=5\" \\\n",
    "  -H \"Authorization: Bearer YOUR_ACCESS_TOKEN\"\n",
    "example_response: |\n",
    "  {\n",
    "    \"data\": [\n",
    "      {\n",
    "        \"id\": \"1234567890\",\n",
    "        \"text\": \"Example tweet content here.\"\n",
    "      }\n",
    "    ],\n",
    "    \"meta\": {\n",
    "      \"result_count\": 1\n",
    "    }\n",
    "  }\n",
    "```\n",
    "\n",
    "**Instructions for User Testing:**\n",
    "- Test the generated YAML in a live application or API tool to ensure correctness.\n",
    "- Validate the endpoint and parameter descriptions against the official API documentation.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95055b8cec006e",
   "metadata": {},
   "source": [
    "### Use Case \n",
    "In this cookbook, we'll take the example of a user who wants to list recent product launches by OpenAI in chronological order. Because the current GPT-4o model has a knowledge cutoff date, it is not expected that the model will know about recent product launches such as the o1-preview model launched in September 2024. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ecc3b9dc1840d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T18:07:34.124609Z",
     "start_time": "2024-09-23T18:07:29.838089Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "tool_name = \"confluence_search_page_content\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e80aeaa52c8dc",
   "metadata": {},
   "source": [
    "Given the knowledge cutoff, as expected the model does not know about the recent product launches by OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d34362ceef5a331",
   "metadata": {},
   "source": [
    "### Setting up a BYOB tool\n",
    "To provide the model with recent events information, we'll follow these steps:\n",
    "\n",
    "##### Step 1: Set Up a Search Engine to Provide Web Search Results\n",
    "##### Step 2: Build a Search Dictionary with Titles, URLs, and Summaries of Web Pages\n",
    "##### Step 3: Pass the information to the model to generate a RAG Response to the User Query  \n",
    "\n",
    "\n",
    "Before we begin, ensure you have the following: **Python 3.12 or later** installed on your machine. You will also need a Google Custom Search API key and Custom Search Engine ID (CSE ID). Necessary Python packages installed: `requests`, `beautifulsoup4`, `openai`. And ensure the OPENAI_API_KEY is set up as an environment variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a766088c001c30b",
   "metadata": {},
   "source": [
    "#### Step 1: Set Up a Search Engine to Provide Web Search Results\n",
    "You can use any publicly available web search APIs to perform this task. We will configure a custom search engine using Google's Custom Search API. This engine will fetch a list of relevant web pages based on the user's query, focusing on obtaining the most recent and pertinent results.  \n",
    "\n",
    "**a. Configure Search API key and Function:** Acquire a Google API key and a Custom Search Engine ID (CSE ID) from the Google Developers Console. You can navigate to this [Programmable Search Engine Link](https://developers.google.com/custom-search/v1/overview) to set up an API key as well as Custom Search Engine ID (CSE ID). \n",
    "\n",
    "The `search` function below sets up the search based on search term, the API and CSE ID keys, as well as number of search results to return. We'll introduce a parameter `site_filter` to restrict the output to only `openai.com`\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7df836efe1589633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T18:08:59.171800Z",
     "start_time": "2024-09-23T18:08:59.164245Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests  # For making HTTP requests to APIs and websites\n",
    "\n",
    "def search(search_item, api_key, cse_id, search_depth=10, site_filter=None):\n",
    "    service_url = 'https://www.googleapis.com/customsearch/v1'\n",
    "\n",
    "    params = {\n",
    "        'q': search_item,\n",
    "        'key': api_key,\n",
    "        'cx': cse_id,\n",
    "        'num': search_depth\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(service_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        results = response.json()\n",
    "\n",
    "        # Check if 'items' exists in the results\n",
    "        if 'items' in results:\n",
    "            if site_filter is not None:\n",
    "                \n",
    "                # Filter results to include only those with site_filter in the link\n",
    "                filtered_results = [result for result in results['items'] if site_filter in result['link']]\n",
    "\n",
    "                if filtered_results:\n",
    "                    return filtered_results\n",
    "                else:\n",
    "                    print(f\"No results with {site_filter} found.\")\n",
    "                    return []\n",
    "            else:\n",
    "                if 'items' in results:\n",
    "                    return results['items']\n",
    "                else:\n",
    "                    print(\"No search results found.\")\n",
    "                    return []\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred during the search: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee6754a2e6cd24",
   "metadata": {},
   "source": [
    "**b. Identify the search terms for search engine:** Before we can retrieve specific results from a 3rd Party API, we may need to use Query Expansion to identify specific terms our browser search API should retrieve. **Query expansion** is a process where we broaden the original user query by adding related terms, synonyms, or variations. This technique is essential because search engines, like Google's Custom Search API, are often better at matching a range of related terms rather than just the natural language prompt used by a user. \n",
    "\n",
    "For example, searching with only the raw query `\"List the latest OpenAI product launches in chronological order from latest to oldest in the past 2 years\"` may return fewer and less relevant results than a more specific and direct search on a succinct phrase such as `\"Latest OpenAI product launches\"`. In the code below, we will use the user's original `search_query` to produce a more specific search term to use with the Google API to retrieve the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3752702114df8160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T18:09:00.816893Z",
     "start_time": "2024-09-23T18:09:00.150843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confluence API search page content\n"
     ]
    }
   ],
   "source": [
    "search_term = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert API documentation assistant. Provide a google search term to find the target API endpoint documentation based on search query provided below in 4-6 words\"},\n",
    "        {\"role\": \"user\", \"content\": search_query}]\n",
    ").choices[0].message.content\n",
    "\n",
    "print(search_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b7194aedbc3a21",
   "metadata": {},
   "source": [
    "**c. Invoke the search function:** Now that we have the search term, we will invoke the search function to retrieve the results from Google search API. The results only have the link of the web page and a snippet at this point. In the next step, we will retrieve more information from the webpage and summarize it in a dictionary to pass to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "891e924b15957206",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T18:09:03.324177Z",
     "start_time": "2024-09-23T18:09:02.671631Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "cse_id = os.getenv('CSE_ID')\n",
    "\n",
    "search_items = search(search_item=search_term, api_key=api_key, cse_id=cse_id, search_depth=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceedee1eb3ffec85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T18:09:04.544840Z",
     "start_time": "2024-09-23T18:09:04.542750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link: https://developer.atlassian.com/cloud/confluence/rest/v1/api-group-search/\n",
      "Snippet: Searches for content using the Confluence Query Language (CQL). Note that CQL input queries submitted through the /wiki/rest/api/search endpoint no longer ...\n",
      "\n",
      "Link: https://community.atlassian.com/t5/Confluence-questions/Rest-API-call-to-search-content-in-a-page-and-it-s-children/qaq-p/999497\n",
      "Snippet: ... search all pages of the parent based on your text string in the search. Here is what an example would look like: http://localhost:8080/confluence/rest/api/ ...\n",
      "\n",
      "Link: https://community.developer.atlassian.com/t/how-to-search-confluence-pages-by-content-state/61595\n",
      "Snippet: Sep 15, 2022 ... The search URL in my case is something like {confluenceBaseURL}/wiki/rest/api/search?cql=content.property%5Bcontent-state-published%5D ...\n",
      "\n",
      "Link: https://community.atlassian.com/t5/Confluence-questions/Searching-for-Page-by-Content/qaq-p/2594304\n",
      "Snippet: Jan 31, 2024 ... ... search API for retrieving the page by using text search. There is a ... search for Confluence content using various fields, operators is the CQL ...\n",
      "\n",
      "Link: https://community.developer.atlassian.com/t/get-a-page-by-its-title/70044\n",
      "Snippet: Jun 5, 2023 ... I would use the search content endpoint (which is not deprecated) and query the page using CQL instead e.g. /wiki/rest/api/content/search ...\n",
      "\n",
      "Link: https://confluence.atlassian.com/confkb/searching-for-content-with-the-rest-api-and-cql-always-limits-results-to-50-1032258424.html\n",
      "Snippet: Nov 25, 2020 ... Searching for content using the REST API and Confluence Query Language (CQL) always returns a maximum of 50 results, despite increasing the limit parameter.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in search_items:\n",
    "    print(f\"Link: {item['link']}\")\n",
    "    print(f\"Snippet: {item['snippet']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f754f92866307e",
   "metadata": {},
   "source": [
    "#### Step 2: Build a Search Dictionary with Titles, URLs, and Summaries of Web Pages\n",
    "After obtaining the search results, we'll extract and organize the relevant information, so it can be passed to the LLM for final output. \n",
    "\n",
    "**a. Scrape Web Page Content:** For each URL in the search results, retrieve the web page to extract textual content while filtering out non-relevant data like scripts and advertisements as demonstrated in function `retrieve_content`. \n",
    "\n",
    "**b. Summarize Content:** Use an LLM to generate concise summaries of the scraped content, focusing on information pertinent to the user's query. Model can be provided the original search text, so it can focus on summarizing the content for the search intent as outlined in function `summarize_content`. \n",
    "  \n",
    "**c. Create a Structured Dictionary:** Organize the data into a dictionary or a DataFrame containing the title, link, and summary for each web page. This structure can be passed on to the LLM to generate the summary with the appropriate citations.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4981ca230333116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T18:09:16.847793Z",
     "start_time": "2024-09-23T18:09:16.616732Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "TRUNCATE_SCRAPED_TEXT = 30000  # Adjust based on your model's context window\n",
    "SEARCH_DEPTH = 5\n",
    "\n",
    "def retrieve_content(url, max_tokens=TRUNCATE_SCRAPED_TEXT):\n",
    "        try:\n",
    "            headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            for script_or_style in soup(['script', 'style']):\n",
    "                script_or_style.decompose()\n",
    "\n",
    "            text = soup.get_text(separator=' ', strip=True)\n",
    "            characters = max_tokens * 4  # Approximate conversion\n",
    "            text = text[:characters]\n",
    "            return text\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to retrieve {url}: {e}\")\n",
    "            return None\n",
    "        \n",
    "def summarize_content(content, search_term, character_limit=500):\n",
    "        prompt = (\n",
    "            f\"You are an AI assistant tasked with summarizing content relevant to '{search_term}'. \"\n",
    "            f\"Please provide a concise summary in {character_limit} characters or less.\"\n",
    "        )\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt},\n",
    "                    {\"role\": \"user\", \"content\": content}]\n",
    "            )\n",
    "            summary = response.choices[0].message.content\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during summarization: {e}\")\n",
    "            return None\n",
    "\n",
    "def get_search_results(search_items, character_limit=500):\n",
    "    # Generate a summary of search results for the given search term\n",
    "    results_list = []\n",
    "    for idx, item in enumerate(search_items, start=1):\n",
    "        url = item.get('link')\n",
    "        \n",
    "        snippet = item.get('snippet', '')\n",
    "        web_content = retrieve_content(url, TRUNCATE_SCRAPED_TEXT)\n",
    "        \n",
    "        if web_content is None:\n",
    "            print(f\"Error: skipped URL: {url}\")\n",
    "        else:\n",
    "            summary = summarize_content(web_content, search_term, character_limit)\n",
    "            result_dict = {\n",
    "                'order': idx,\n",
    "                'link': url,\n",
    "                'title': snippet,\n",
    "                'Summary': summary\n",
    "            }\n",
    "            results_list.append(result_dict)\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b9afc6c933a6a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T18:09:36.415639Z",
     "start_time": "2024-09-23T18:09:17.743365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search order: 1\n",
      "Link: https://developer.atlassian.com/cloud/confluence/rest/v1/api-group-search/\n",
      "Snippet: Searches for content using the Confluence Query Language (CQL). Note that CQL input queries submitted through the /wiki/rest/api/search endpoint no longer ...\n",
      "Summary: The Confluence Cloud REST API provides a comprehensive suite of tools for developers, including authentication, content management (attachments, comments, labels, properties, permissions), space management, and user management. It supports both REST and GraphQL APIs, allowing for dynamic interactions with content and settings. The API documentation includes guides, changelogs, and support resources. Users can rate the utility of the page, access system status updates, and review privacy policies. Overall, the Confluence API facilitates tailored content management and integration capabilities.\n",
      "--------------------------------------------------------------------------------\n",
      "Search order: 2\n",
      "Link: https://community.atlassian.com/t5/Confluence-questions/Rest-API-call-to-search-content-in-a-page-and-it-s-children/qaq-p/999497\n",
      "Snippet: ... search all pages of the parent based on your text string in the search. Here is what an example would look like: http://localhost:8080/confluence/rest/api/ ...\n",
      "Summary: The content discusses using the Confluence REST API to implement a search feature within a page and its children. A user seeks to replicate the search functionality of Confluence by making API calls that return page titles matching a query under a specified parent page ID. The suggested API endpoint is `/rest/api/search` with a CQL query to filter results based on the parent page. However, an issue arises where the search only returns immediate children. Follow-up guidance is offered to troubleshoot the CQL and ensure it covers all nested levels.\n",
      "--------------------------------------------------------------------------------\n",
      "Search order: 3\n",
      "Link: https://community.developer.atlassian.com/t/how-to-search-confluence-pages-by-content-state/61595\n",
      "Snippet: Sep 15, 2022 ... The search URL in my case is something like {confluenceBaseURL}/wiki/rest/api/search?cql=content.property%5Bcontent-state-published%5D ...\n",
      "Summary: The discussion revolves around searching Confluence pages by their content state using the Confluence API. Users have pointed out that although content statuses (like archived and current) can be searched using CQL, there is no direct way to query custom content states (like rough draft or in progress). While a CQL was attempted to query by a content property representing published states, it led to errors. Further, users confirmed that there is no current method to filter by these custom states and encouraged filing feature requests for this functionality on Atlassian’s public Jira.\n",
      "--------------------------------------------------------------------------------\n",
      "Search order: 4\n",
      "Link: https://community.atlassian.com/t5/Confluence-questions/Searching-for-Page-by-Content/qaq-p/2594304\n",
      "Snippet: Jan 31, 2024 ... ... search API for retrieving the page by using text search. There is a ... search for Confluence content using various fields, operators is the CQL ...\n",
      "Summary: In the Atlassian Community post, a user seeks guidance on searching Confluence pages by content using the REST API. They mention using the v2 API for page title search but require a solution to search by keywords. Community leaders recommend using the CQL (Confluence Query Language) with the v1 API endpoint for content search. They confirm that the CQL search results include content IDs, which can help in constructing URLs for downloading and redirecting content. The user also explores building URLs based on API responses and queries the safety and current status of the API mentioned.\n",
      "--------------------------------------------------------------------------------\n",
      "Search order: 5\n",
      "Link: https://community.developer.atlassian.com/t/get-a-page-by-its-title/70044\n",
      "Snippet: Jun 5, 2023 ... I would use the search content endpoint (which is not deprecated) and query the page using CQL instead e.g. /wiki/rest/api/content/search ...\n",
      "Summary: The Confluence API discussion revolves around retrieving a page by its title after the deprecation of the v1 API content call. Users are advised to use the search content endpoint with CQL queries instead, despite concerns over slower performance and migration challenges. Specific issues arise with titles containing special characters, leading to bugs and errors. A workaround involves sanitizing queries to use the CONTAINS operator for special characters. Recently, updates have been made that resolved some issues with API calls for retrieving pages by title.\n",
      "--------------------------------------------------------------------------------\n",
      "Search order: 6\n",
      "Link: https://confluence.atlassian.com/confkb/searching-for-content-with-the-rest-api-and-cql-always-limits-results-to-50-1032258424.html\n",
      "Snippet: Nov 25, 2020 ... Searching for content using the REST API and Confluence Query Language (CQL) always returns a maximum of 50 results, despite increasing the limit parameter.\n",
      "Summary: The Confluence API has a default limit on search results. When using the REST API with Confluence Query Language (CQL), results are capped at 50 if the \"body\" expansion is included. The maximum can reach 1000 without any expansions or up to 200 with other expansions. To retrieve more results, avoid using the \"body\" expansion in your query. For instance, you can modify your API call to include only \"space\" and \"history.lastUpdated\" for a higher limit.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = get_search_results(search_items)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Search order: {result['order']}\")\n",
    "    print(f\"Link: {result['link']}\")\n",
    "    print(f\"Snippet: {result['title']}\")\n",
    "    print(f\"Summary: {result['Summary']}\")\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0603ea9003f7c1d",
   "metadata": {},
   "source": [
    "We retrieved the most recent results. (Note these will vary depending on when you execute this script.) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f81cf3fd1a942c3",
   "metadata": {},
   "source": [
    "#### Step 3: Pass the information to the model to generate a RAG Response to Narrow down the target webpage\n",
    "With the search data organized in a JSON data structure, we will pass this information to the LLM to narrow down relevant webpage. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2894a01ce6c44d36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T18:17:27.936015Z",
     "start_time": "2024-09-23T18:17:09.751583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECTED ORDER: 1\n",
      "URL: https://developer.atlassian.com/cloud/confluence/rest/v1/api-group-search/\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "# final_prompt = (\n",
    "#     f\"The user will provide a dictionary of search results in JSON format for search query {search_term} Based on on the search results provided by the user, provide a detailed response to this query: **'{search_query}'**. Make sure to cite all the sources at the end of your answer.\"\n",
    "# )\n",
    "\n",
    "prompt = f\"\"\"\n",
    "**System Instruction**\n",
    "You are an expert API documentation assistant. Your task is to understand the user's query on specific API endpoint, synthesize the relevant webpages from a given online search result, and select the most relevant webpage that have information on the given API endpoint and its YAML configuration in order to write a python calling request to the API.\n",
    "\n",
    "**Expected Output:**\n",
    "SELECTED ORDER: <order>\n",
    "URL: <URL>\n",
    "\n",
    "**Explanation:**\n",
    "- Replace `<order>` with the selected order number from the search results and `<URL>` with the selected URL from the search results.\n",
    "- Set <order> to -1 if the search results do not provide enough information on the user input API endpoint.\n",
    "\n",
    "**User Input:**\n",
    "The user endpoint query is: {tool_name}\n",
    "The google search query for this endpoint is: {search_term}\n",
    "The search results are: {results}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(results)}],\n",
    "    temperature=0\n",
    "\n",
    ")\n",
    "summary = response.choices[0].message.content\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "405b31f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected order: 1\n"
     ]
    }
   ],
   "source": [
    "# Parse the response to get the selected order and URL\n",
    "\n",
    "selected_order = int(summary.split('\\n')[0].split(': ')[1])\n",
    "\n",
    "print(f\"Selected order: {selected_order}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ebe3b7",
   "metadata": {},
   "source": [
    "#### Step 4: Visit the related search results and retrieve the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c681f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = results[selected_order-1]['link']\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    main_content = soup.find('body') or soup.find('div', class_='content') or soup.find('article')\n",
    "    \n",
    "    if main_content:\n",
    "        print(len(main_content.get_text(strip=True)))\n",
    "        # print(main_content.get_text(strip=True))\n",
    "    else:\n",
    "        print(\"Body content not found\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error fetching the URL: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba3bc0",
   "metadata": {},
   "source": [
    "### Step 5: Extract the API specs from the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17f04c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated YAML Configuration:\n",
      "Based on the search query \"Confluence API search page content,\" I will provide a YAML configuration for the Confluence API endpoint that allows searching page content. Here is the synthesized information and YAML configuration:\n",
      "\n",
      "```yaml\n",
      "name: confluence_search_page_content\n",
      "servers:\n",
      "  - url: https://developer.atlassian.com/cloud/confluence/rest/api-group-search/\n",
      "    description: Main server for Confluence Cloud REST API\n",
      "description: Searches for content in Confluence pages using CQL (Confluence Query Language).\n",
      "method: GET\n",
      "endpoint: https://your-domain.atlassian.net/wiki/rest/api/content/search\n",
      "parameters:\n",
      "  - name: cql\n",
      "    type: string\n",
      "    required: true\n",
      "    description: The CQL query to execute for searching content.\n",
      "  - name: limit\n",
      "    type: integer\n",
      "    required: false\n",
      "    description: The maximum number of results to return.\n",
      "  - name: start\n",
      "    type: integer\n",
      "    required: false\n",
      "    description: The starting index of the returned results.\n",
      "  - name: expand\n",
      "    type: string\n",
      "    required: false\n",
      "    description: A comma-separated list of properties to expand in the response.\n",
      "example_request: |\n",
      "  curl -X GET \"https://your-domain.atlassian.net/wiki/rest/api/content/search?cql=type=page&limit=5\" \\\n",
      "  -H \"Authorization: Bearer YOUR_ACCESS_TOKEN\" \\\n",
      "  -H \"Accept: application/json\"\n",
      "example_response: |\n",
      "  {\n",
      "    \"results\": [\n",
      "      {\n",
      "        \"id\": \"123456\",\n",
      "        \"type\": \"page\",\n",
      "        \"title\": \"Example Page Title\",\n",
      "        \"space\": {\n",
      "          \"key\": \"EX\",\n",
      "          \"name\": \"Example Space\"\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"start\": 0,\n",
      "    \"limit\": 5,\n",
      "    \"size\": 1\n",
      "  }\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- **name**: The endpoint name is prefixed with \"confluence\" to indicate the service provider.\n",
      "- **servers**: The URL provided is the main documentation page for the Confluence Cloud REST API.\n",
      "- **description**: A brief description of the endpoint's functionality.\n",
      "- **method**: The HTTP method used for this endpoint is GET.\n",
      "- **endpoint**: The full URL for the API endpoint, with a placeholder for the domain.\n",
      "- **parameters**: A list of parameters that can be used with this endpoint, including their types and descriptions.\n",
      "- **example_request**: An example cURL request demonstrating how to use the endpoint.\n",
      "- **example_response**: A sample JSON response from the API.\n"
     ]
    }
   ],
   "source": [
    "def generate_api_spec(webpage_content, tool_name, search_term):\n",
    "    userPrompt = f\"\"\"\n",
    "    The user endpoint query is: {tool_name}\n",
    "    The google search query for this endpoint is: {search_term}\n",
    "    The first search result is: {webpage_content}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": systemPrompt_final},\n",
    "                {\"role\": \"user\", \"content\": userPrompt}\n",
    "            ],\n",
    "            temperature=0.1\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating YAML config: {e}\")\n",
    "        return None\n",
    "\n",
    "# Get the webpage content\n",
    "webpage_content = main_content.get_text(strip=True)\n",
    "\n",
    "# Extract YAML configuration\n",
    "yaml_config = generate_api_spec(webpage_content, tool_name, search_term)\n",
    "print(\"\\nGenerated YAML Configuration:\")\n",
    "print(yaml_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40640c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated YAML Configuration (o1):\n",
      "Here is the YAML configuration for the Confluence API \"search page content\" endpoint:\n",
      "\n",
      "```yaml\n",
      "name: Confluence_API_Search_Page_Content\n",
      "servers:\n",
      "  - url: https://developer.atlassian.com/cloud/confluence/rest/api-group-content/\n",
      "    description: Confluence REST API Documentation\n",
      "description: |\n",
      "  Searches for page content in Confluence using Confluence Query Language (CQL).\n",
      "method: GET\n",
      "endpoint: https://api.atlassian.com/ex/confluence/{cloudId}/wiki/rest/api/content/search\n",
      "parameters:\n",
      "  - name: cql\n",
      "    type: string\n",
      "    required: true\n",
      "    description: The CQL query to search for content.\n",
      "  - name: cqlContext\n",
      "    type: string\n",
      "    required: false\n",
      "    description: The context in which the CQL query is executed.\n",
      "  - name: limit\n",
      "    type: integer\n",
      "    required: false\n",
      "    description: The maximum number of results to return.\n",
      "  - name: start\n",
      "    type: integer\n",
      "    required: false\n",
      "    description: The starting index of the first result.\n",
      "  - name: expand\n",
      "    type: string\n",
      "    required: false\n",
      "    description: Comma-separated list of fields to expand in the response.\n",
      "example_request: |\n",
      "  curl -X GET \"https://api.atlassian.com/ex/confluence/{cloudId}/wiki/rest/api/content/search?cql=type=page&limit=10\" \\\n",
      "  -H \"Authorization: Bearer YOUR_ACCESS_TOKEN\"\n",
      "example_response: |\n",
      "  {\n",
      "    \"results\": [\n",
      "      {\n",
      "        \"id\": \"123456\",\n",
      "        \"type\": \"page\",\n",
      "        \"title\": \"Example Page\",\n",
      "        \"space\": {\n",
      "          \"key\": \"DEMO\",\n",
      "          \"name\": \"Demo Space\"\n",
      "        },\n",
      "        \"body\": {\n",
      "          \"storage\": {\n",
      "            \"value\": \"<p>Page content here.</p>\",\n",
      "            \"representation\": \"storage\"\n",
      "          }\n",
      "        },\n",
      "        \"version\": {\n",
      "          \"number\": 2\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"size\": 1,\n",
      "    \"start\": 0,\n",
      "    \"limit\": 10\n",
      "  }\n",
      "```\n",
      "\n",
      "### Instructions for User Testing:\n",
      "- **Validate the YAML Structure:** Use a YAML validator to ensure the configuration adheres to proper syntax.\n",
      "- **Test with API Tools:** Import the YAML into an API tool like Postman or Swagger to verify endpoint accessibility and parameter functionality.\n",
      "- **Cross-Check with Official Documentation:** Compare the endpoint details, parameters, and response structure with the [Confluence REST API Documentation](https://developer.atlassian.com/cloud/confluence/rest/api-group-content/#api-content-search-get) to ensure accuracy.\n"
     ]
    }
   ],
   "source": [
    "def generate_api_spec_o1(webpage_content, tool_name, search_term):\n",
    "    userPrompt = f\"\"\"\n",
    "    The user endpoint query is: {tool_name}\n",
    "    The google search query for this endpoint is: {search_term}\n",
    "    The first search result is: {webpage_content}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"o1-mini-2024-09-12\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": systemPrompt_final + userPrompt}\n",
    "            ],\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating YAML config: {e}\")\n",
    "        return None\n",
    "\n",
    "# Get the webpage content\n",
    "webpage_content = main_content.get_text(strip=True)\n",
    "\n",
    "# Extract YAML configuration\n",
    "yaml_config = generate_api_spec_o1(webpage_content, tool_name, search_term)\n",
    "print(\"\\nGenerated YAML Configuration (o1):\")\n",
    "print(yaml_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6beba8859f1bc7",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    " \n",
    "Large Language Models (LLMs) have a knowledge cutoff and may not be aware of recent events. To provide them with the latest information, you can build a Bring Your Own Browser (BYOB) tool using Python. This tool retrieves current web data and feeds it to the LLM, enabling up-to-date responses.\n",
    "\n",
    "The process involves three main steps:\n",
    "\n",
    "**#1 Set Up a Search Engine:** Use a public search API, like Google's Custom Search API, to perform web searches and obtain a list of relevant search results.  \n",
    "\n",
    "**#2 Build a Search Dictionary:** Collect the title, URL, and a summary of each web page from the search results to create a structured dictionary of information.  \n",
    "\n",
    "**#3. Generate a RAG Response:** Implement Retrieval-Augmented Generation (RAG) by passing the gathered information to the LLM, which then generates a final response to the user's query.\n",
    "\n",
    "By following these steps, you enhance the LLMs ability to provide up-to-date answers in your application that include the most recent developments, such as the latest product launches by OpenAI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
